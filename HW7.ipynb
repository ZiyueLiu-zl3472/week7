{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPB1zU11vrkaW5VUQYWEZ2F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZiyueLiu-zl3472/week7/blob/main/HW7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLRoIfbgnFrd",
        "outputId": "beb8d0f0-3064-4583-e392-e7956586bc2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected Shortfall (confidence=0.8): 60.0\n",
            "Expected Shortfall (VaR=80): 90.0\n",
            "Test Passed (alpha): False\n",
            "Test Passed (VaR): True\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# qTMat1\n",
        "def TMAT1(vec1, vec2):\n",
        "    categories = np.unique(vec1)\n",
        "    n = len(categories)\n",
        "    count_mat = np.zeros((n, n))\n",
        "\n",
        "\n",
        "    for last_rating, now_rating in zip(vec1, vec2):\n",
        "        i = np.where(categories == last_rating)[0][0]\n",
        "        j = np.where(categories == now_rating)[0][0]\n",
        "        count_mat[i, j] += 1\n",
        "\n",
        "    # Normalize each row to convert counts into probabilities\n",
        "    row_sums = count_mat.sum(axis=1, keepdims=True)\n",
        "    # Avoid division by zero (in case a category doesn't appear in vec1)\n",
        "    row_sums[row_sums == 0] = 1\n",
        "    transition_mat = count_mat / row_sums\n",
        "\n",
        "    return transition_mat\n",
        "\n",
        "    pass\n",
        "\n",
        "# qTMat2\n",
        "import numpy as np\n",
        "\n",
        "def Forecast_nPeriod(vec, tmat, n):\n",
        "    out = np.eye(tmat.shape[0])  # identity matrix\n",
        "    for _ in range(n):\n",
        "        out = np.dot(out, tmat)  # multiply T n times\n",
        "    out = np.dot(vec, out)       # multiply the initial vector by T^n\n",
        "    return out\n",
        "\n",
        "# qTmat2Bonus\n",
        "def Forecast_nPeriod_Recursive(vec, mat, n):\n",
        "    if n == 0:\n",
        "        return vec\n",
        "\n",
        "    # Recursive step: multiply once by mat, then recurse for n - 1 steps\n",
        "    next_vec = np.dot(vec, mat)\n",
        "    return Forecast_nPeriod_Recursive(next_vec, mat, n - 1)\n",
        "\n",
        "    pass\n",
        "\n",
        "# qGetBondDuration\n",
        "def getBondDuration(y, face, couponRate, m, ppy=1):\n",
        "    n = m * ppy\n",
        "    i = y / ppy\n",
        "    c = face * couponRate / ppy\n",
        "\n",
        "    sumW = 0.0\n",
        "    sumPVCF = 0.0\n",
        "\n",
        "    for t in range(1, n + 1):\n",
        "        if t < n:\n",
        "            CF_t = c\n",
        "        else:\n",
        "            CF_t = c + face\n",
        "\n",
        "        pv_cf = CF_t / ((1 + i) ** t)\n",
        "\n",
        "        sumW += (t / ppy) * pv_cf\n",
        "        sumPVCF += pv_cf\n",
        "\n",
        "    # Macaulay duration in years\n",
        "    duration = sumW / sumPVCF\n",
        "    return duration\n",
        "\n",
        "# qGetReturnsLag\n",
        "def getReturns(pricevec, lag=1):\n",
        "    prices = np.array(pricevec, dtype=float)\n",
        "\n",
        "    returns = [(prices[i] - prices[i - lag]) / prices[i - lag]\n",
        "               for i in range(lag, len(prices))]\n",
        "\n",
        "    return np.array(returns)\n",
        "\n",
        "    pass\n",
        "\n",
        "# qVAR\n",
        "from scipy.stats import norm\n",
        "\n",
        "def VaR(r, confidence,principal=1):\n",
        "\n",
        "    plt.hist(r, bins=50)\n",
        "    plt.show()\n",
        "\n",
        "    # Compute the (1 - confidence) percentile (lower tail)\n",
        "    q = np.quantile(r, 1 - confidence)\n",
        "\n",
        "    # Return the absolute value (positively stated) scaled by principal\n",
        "    out = abs(q) * principal\n",
        "    return out\n",
        "\n",
        "\n",
        "# qES\n",
        "def ES(losses, confidence=None, VaR=None):\n",
        "\n",
        "    if VaR is not None:\n",
        "        # Use the provided VaR to calculate Expected Shortfall:\n",
        "        # Average all losses that are greater than the provided VaR.\n",
        "        out = losses[losses > VaR].mean()\n",
        "    else:\n",
        "        # Calculate VaR at the given alpha percentile if VaR is not provided.\n",
        "        # Since losses are positive numbers, worse losses are higher values.\n",
        "        VaR = np.percentile(losses, 100 * (1 - confidence))\n",
        "        out = losses[losses > VaR].mean()\n",
        "\n",
        "    return out\n",
        "\n",
        "    pass"
      ]
    }
  ]
}